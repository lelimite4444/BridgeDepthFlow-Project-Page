<!doctype html>
<html lang="en" class="no-js">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="canonical" href="https://html5-templates.com/" />
    <title>Video Compression through Image Interpolation</title>
    <link rel=icon href=images/nctu.png>
    <meta name="description" content="Simplified Bootstrap template with sticky menu">
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/sticky-menu.css" rel="stylesheet">
</head>
<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header page-scroll">
                <a class="navbar-brand page-scroll" href="#page-top">BridgeDepthFlow</a>
            </div>

            <div class="collapse navbar-collapse navbar-ex1-collapse">
                <ul class="nav navbar-nav">
                    <li class="hidden">
                        <a class="page-scroll" href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#abstract">Abstract</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#method">Method</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#results">Results</a>
                    </li>
		    <li>
                        <a class="page-scroll" href="#citation">Citation</a>
                    </li>
		    <li>
                        <a class="page-scroll" href="#acknowledgement">Acknowledgement</a>
                    </li>
                </ul>
            </div>	<!-- .navbar-collapse -->
        </div>		<!-- .container -->
    </nav>
    <!-- Welcome   -->
    <!--section id="welcome" class="welcome-section"-->
	<br><br><br><br><br>
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h1><p style="text-align:center;">Bridging Stereo Matching and Optical Flow via <br>Spatiotemporal Correspondence</p></h1>
                    <div class="authors"><h3>
			<p style="text-align:center;">
			<a href="https://lelimite4444.github.io/" target="_blank">Hsueh-Ying Lai<sup>1</sup></a>,
			<a href="https://sites.google.com/site/yihsuantsai/" target="_blank">Yi-Hsuan Tsai<sup>2</sup></a>,
			<a href="https://walonchiu.github.io/" target="_blank">Wei-Chen Chiu<sup>1</sup></a>,
			</p>
			<br>
			<p style="text-align:center;">
			<sup>1</sup> National Chiao Tung University,
			<sup>2</sup> NEC Labs America
			<br><br>
			<a href="https://www.nctu.edu.tw/en" target="_blank"><img src="images/nctu.png" height="100"></a>&nbsp;&nbsp;
			<a href="http://www.nec-labs.com/research-departments/media-analytics/media-analytics-home" target="_blank"><img src="images/nec.jpg" height="100"></a>
			</p></h3>
		    </div>

                </div>
            </div>
        </div>
	<br><br>
        <div class="container" id="teaser">
            <div class="row">
                <p style="text-align:center;">
                <img src="images/teaser.png" height="500" style="padding-right:25px;">
		</p>
                <figcaption>
		<p style="text-align:left;">
		Using temporally adjacent stereo pairs as input, our model can estimate the correspondence maps of each pair via geometric connections, thus bridging stereo matching and optical flow through multiple reconstruction, forming a cycle.
		</p>
		</figcaption>
            </div>
        </div>
	    
    <!--/section-->

    <!-- About -->
	
        <div class="container" id="abstract">
            <div class="row">
                
		    <h1>Abstract</h1>
		    <h4 small><p style="text-align:left; font-family: 'Lato'; line-height: 150%">Stereo matching and flow estimation are two essential tasks for scene understanding, spatially in 3D and temporally in motion.

Existing approaches have been focused on the unsupervised setting due to the limited resource to obtain the large-scale ground truth data.

To construct a self-learnable objective, co-related tasks are often linked together to form a joint framework.

However, the prior work usually utilizes independent networks for each task, thus not allowing to learn shared feature representations across models. 

In this paper, we propose a single and principled network to jointly learn spatiotemporal correspondence for stereo matching and flow estimation, with a newly designed geometric connection as the unsupervised signal for temporally adjacent stereo pairs.

We show that our method performs favorably against several state-of-the-art baselines for both unsupervised depth and flow estimation on the KITTI benchmark dataset.</p></h4 small>
                
            </div>
        </div>
    
	<div class="container" id="method">
            <div class="row">
		<h1>Method</h1>
		<p style="text-align:center;">
                <img src="images/model.png" height="500" style="padding-right:25px;">
		</p>
                <figcaption>
		<p style="text-align:left;">
			Overall structure of our method. Our framework consists of a single model <l>P</l> that estimates dense correspondence maps based on the order of two input images for both stereo matching and optical flow.
			Each pair can be fed into <l>P</l> but in a different image order (e.g., (<l>I<sup>l</sup></l>, <l>I<sup>r</sup></l>) and (<l>I<sup>r</sup></l>, <l>I<sup>l</sup></l>)), and thus two reconstruction loss <l>L<sub>rec</sub></l> are able to be optimized based on two warping functions <l>W</l> obtained from each pair.
%
  Between these two tasks, two difference are: (1) we apply left-right consistency <l>L<sub>lr</sub></l> to stabilize the stereo matching part only; (2) occlusion map derived from the correspondence maps of two opposite directions is adopted on the reconstruction loss for solving the largely occluded area for optical flow only.
		</p>
		</figcaption>
	    </div>
	</div>
	
	<div class="container" id="results">
            <div class="row">
		<h1>Results</h1>
                <p style="text-align:center;">
                <img src="images/results.png" height="500" style="padding-right:25px;">
		</p>
		<figcaption>
		<p style="text-align:left;">
		    Example results on KITTI. In each row, we sequentially show the left image at time t, our predicted depth map, the ground truth
depth, our flow prediction, and the ground truth flow
		</p>
		</figcaption>
            </div>
        </div>
	
	<div class="container" id="citation">
            <div class="row">
		<h1>Citation</h1>
                <p>Bridging Stereo Matching and Optical Flow via Spatiotemporal Correspondence</p>
                <a href="mailto:lelimite4444@gmail.com" target="_blank">Hsueh-Ying Lai</a>,
    	 	<a href="mailto:ytsai@nec-labs.com" target="_blank">Yi-Hsuan Tsai</a>,
    		<a href="mailto:walon@cs.nctu.edu.tw" target="_blank">Wei-Chen Chiu</a>
		    
		<center>
            	    <div class="thumbs">
			<p style="text-align:left;">
            		<img src="images/pg00010.jpg" width=13%>
            		<img src="images/pg00020.jpg" width=13%>
            		<img src="images/pg00030.jpg" width=13%>
            		<img src="images/pg00040.jpg" width=13%>
            		<img src="images/pg00050.jpg" width=13%>
            		<img src="images/pg00060.jpg" width=13%>
            		<img src="images/pg00070.jpg" width=13%><br>
			<img src="images/pg00080.jpg" width=13%>
            		<img src="images/pg00090.jpg" width=13%>
            		<img src="images/pg00100.jpg" width=13%>
            		<img src="images/pg00110.jpg" width=13%>
            		<img src="images/pg00120.jpg" width=13%>
            		<img src="images/pg00130.jpg" width=13%>
			</p>
        	    </div>
    		</center>
		<a href="https://arxiv.org/pdf/1905.09265.pdf" target="_blank"><img src="images/pdf.png">Paper (arXiv)</a>&nbsp;
	        <a href="https://github.com/lelimite4444/BridgeDepthFlow" target="_blank"><img src="images/code.png", height=40, style="padding-right:8px;">Source Code</a>

	        <pre class="highlight">
	    	    @inproceedings{lai19cvpr,
 		    title = {Bridging Stereo Matching and Optical Flow via Spatiotemporal Correspondence},
 		    author = {Hsueh-Ying Lai and Yi-Hsuan Tsai and Wei-Chen Chiu},
 		    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 		    year = {2019}}
	    	</pre>

            </div>
        </div>
	
	<div class="container" id="acknowledgement">
            <div class="row">
		    <h1>Acknowledgement</h1>
                
            </div>
        </div>
	
	<a id="back2Top" title="Back to top" href="#">&#10148;</a>
	
    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Scrolling Nav JavaScript -->
    <script src="js/jquery.easing.min.js"></script>
    <script src="js/sticky-menu.js"></script>

</body>

</html>
